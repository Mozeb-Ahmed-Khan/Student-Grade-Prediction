{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/8Fm6Q/IbluGyyyQwlpUi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3utAM-_T1cs","executionInfo":{"status":"ok","timestamp":1714849353430,"user_tz":-300,"elapsed":28531,"user":{"displayName":"Ayesha Saqib","userId":"15307684901972161499"}},"outputId":"83d4bb7e-307e-4b29-97b5-9d1f94b6715b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn import tree\n","\n","def specificity(tn,fp):\n","  return (tn) / (tn + fp);\n","def sensitivity(tp,fn):\n","  return  (tp) / (tp + fn);\n","def accuracy(tn, fp, fn, tp):\n","  return (tp+ tn)/(tn+ fp+ fn+ tp);\n","def calculate_scores(row):\n","    row=sorted(row,reverse=True)\n","    return row\n","assign_header = lambda column, header: pd.DataFrame({header: column})"],"metadata":{"id":"RyJcx0_IAy85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Om3cPBZ7A7k6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Qaw70i28A8mo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################################part I#############################################\n","\n","Totals_A= {'As:1': 60, 'As:2':   100, 'As:3': 140, 'As:4': 80}\n","Totals_Q= {'Qz:1': 10, 'Qz:2': 10, 'Qz:3': 10, 'Qz:4': 10}\n","\n","filename='drive/MyDrive/DataMining/DataMiningDataset.xlsx'\n","df = pd.read_excel(filename)\n","df=df[3:]\n","\n","#preprocessing\n","df = df.fillna(0)\n","\n","#for 1st column   df.iloc[:,1]\n","#for 1st row   df[:1]\n","\n","#data of assignments for part 1\n","Assign_data_part_I=df.iloc[:,1:5]\n","Assign_data_part_I=((Assign_data_part_I/Totals_A)*3)\n","#print(Assign_data_part_I)\n","\n","\n","#data of quizzes for part 1\n","quiz_data_part_I=df.iloc[:,8:12]\n","quiz_data_part_I=((quiz_data_part_I/Totals_Q)*2)\n","#print(quiz_data_part_I)\n","\n","#data of quizzes for part 1\n","sessional_data_part_I=df.iloc[:,16]\n","sessional_data_part_I=(sessional_data_part_I/15)*15\n","#print(sessional_data_part_I)\n","\n","#data of Grades for part 1\n","Grades_data_part_I=df.iloc[:,18]\n","#print(Grades_data_part_I)\n","\n","header = 'S-I'\n","sessional_data_part_I= assign_header(sessional_data_part_I, header)\n","\n","header = 'Grades'\n","Grades_data_part_I= assign_header(Grades_data_part_I, header)\n","\n","# Concatenate DataFrames vertically (along rows)\n","df_part_I = pd.concat([Assign_data_part_I,quiz_data_part_I,sessional_data_part_I,Grades_data_part_I], axis=1)\n","\n","#data for part 1\n","print(df_part_I)\n","\n","\n","x,y=df_part_I.iloc[:,1:8],df_part_I.iloc[:,9]\n","y= assign_header(y, 'Grades')\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","# Create a KNeighborsClassifier instance with k=3\n","knn = KNeighborsClassifier(n_neighbors=3)\n","\n","# Train the model\n","knn.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = knn.predict(X_test)\n","\n","# Calculate confusion matrix\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","\n","# Calculate specificity\n","specificity_KNN = specificity(tn , fp)\n","specificity_KNN=round(specificity_KNN,3)\n","\n","# Calculate sensitivity\n","sensitivity_KNN = sensitivity(tp , fn)\n","sensitivity_KNN=round(sensitivity_KNN,3)\n","\n","# Calculate accuracy\n","accuracy_KNN = accuracy(tn, fp, fn, tp)\n","accuracy_KNN=round(accuracy_KNN,3)\n","\n","\n","# Evaluate the accuracy of the model\n","accuraccy = accuracy_score(y_test, y_pred)\n","\n","accuraccy =round(accuraccy,3)\n","print('')\n","print(\"\\n\\n\\n\\t Results of part I (K Nearest Neighbour) \\n \")\n","print(\"Accuracy of KNN           :\", accuraccy)\n","print(\"Accuracy(build in) of KNN :\", accuracy_KNN)\n","print(\"Specificity of KNN        :\", specificity_KNN)\n","print(\"Sensitivity of KNN        :\", sensitivity_KNN)\n","\n","\n","# Create the decision tree classifier\n","clf = tree.DecisionTreeClassifier(criterion='entropy')\n","\n","# Train the tree with the data\n","clf = clf.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = clf.predict(X_test)\n","\n","true_n, false_p, false_n, true_p = confusion_matrix(y_test, y_pred).ravel()\n","\n","# Calculate specificity\n","specificity_DT =specificity(true_n, false_p)\n","specificity_DT =round(specificity_DT,3)\n","\n","# Calculate sensitivity\n","sensitivity_DT = sensitivity(true_p , false_n)\n","sensitivity_DT =round(sensitivity_DT,3)\n","\n","# Evaluate the accuracy of the model\n","accuracy_DT = accuracy_score(y_test, y_pred)\n","accuracy_DT =round(accuracy_DT,3)\n","\n","print(\"\\n\\n\\n\\t Results of part I (Decision Tree) \\n \")\n","print(\"Accuracy of DT   :\", accuracy_DT)\n","print(\"Specificity of DT:\", specificity_DT)\n","print(\"Sensitivity of DT:\", sensitivity_DT)\n","print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZR2tm-gdUS97","executionInfo":{"status":"ok","timestamp":1714850721204,"user_tz":-300,"elapsed":370,"user":{"displayName":"Ayesha Saqib","userId":"15307684901972161499"}},"outputId":"0ad636ae-51e6-4001-f4f4-4c5604cedd1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     As:1  As:2      As:3     As:4  Qz:1  Qz:2  Qz:3  Qz:4   S-I Grades\n","3   1.975  2.70  2.571429  3.00000   1.5   0.9   0.9   0.0  9.75   Pass\n","4   2.000  1.86  1.992857  1.21875   0.3   0.0   0.1   0.0  3.37   Fail\n","5   2.125  1.89  2.571429  2.32500   0.0   0.0   0.2   0.0  6.56   Fail\n","6   1.025  1.26  1.285714  2.62500   0.2   0.4   0.0   0.0  5.06   Fail\n","7   2.150  1.95  2.678571  0.37500   0.6   0.2   0.0   0.0  4.50   Fail\n","..    ...   ...       ...      ...   ...   ...   ...   ...   ...    ...\n","67  2.350  2.16  1.285714  1.87500   0.9   0.0   0.0   0.2  2.43   Fail\n","68  2.150  2.13  2.678571  1.95000   0.6   0.4   1.2   0.0  7.31   Fail\n","69  2.475  2.16  1.392857  1.23750   0.6   0.2   0.4   0.0  3.75   Fail\n","70  2.150  2.79  2.678571  2.43750   0.6   0.0   0.6   0.0  1.87   Fail\n","71  2.400  2.37  2.678571  2.62500   0.5   0.0   1.5   0.5  5.06   Pass\n","\n","[69 rows x 10 columns]\n","\n","\n","\n","\n","\t Results of part I (K Nearest Neighbour) \n"," \n","Accuracy of KNN           : 0.929\n","Accuracy(build in) of KNN : 0.929\n","Specificity of KNN        : 1.0\n","Sensitivity of KNN        : 0.833\n","\n","\n","\n","\t Results of part I (Decision Tree) \n"," \n","Accuracy of DT   : 0.714\n","Specificity of DT: 0.5\n","Sensitivity of DT: 1.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]}]},{"cell_type":"code","source":["\n","from sklearn.metrics import accuracy_score\n","filename='drive/MyDrive/DataMining/DataMiningDataset.xlsx'\n","df = pd.read_excel(filename)\n","df=df[3:]\n","\n","#preprocessing\n","df = df.fillna(0)\n","#print(df.head())\n","\n","Totals_A= {'As:1': 60, 'As:2':   100, 'As:3': 140, 'As:4': 80, 'As:5': 120, 'As:6': 80}\n","Totals_Q= {'Qz:1': 10, 'Qz:2': 10, 'Qz:3': 10, 'Qz:4': 10, 'Qz:5': 10, 'Qz:6': 10}\n","\n","df_Assign_part_2=df.iloc[:,1:7]\n","df_Assign_abs_part_2=(df_Assign_part_2/Totals_A)*3\n","#print(df_Assign_abs_part_2)\n","\n","# Apply the scoring function row-wise\n","scores_list = []\n","for index, row in df_Assign_abs_part_2.iterrows():\n","    scores = calculate_scores(row)\n","    scores_list.append(scores)\n","df_Assign_abs_part_2 = pd.DataFrame(scores_list, columns=['A1', 'A2', 'A3', 'A4', 'A5','A6'])\n","\n","df_Assign_abs_part_2 = df_Assign_abs_part_2.iloc[:, :-1]\n","df_Assign_abs_part_2=df_Assign_abs_part_2.round(2)\n","#print(df_Assign_abs_part_2)\n","\n","\n","df_quiz_part_2=df.iloc[:,8:14]\n","df_quiz_abs_part_2=(df_quiz_part_2/Totals_Q)*2\n","#print(df_quiz_abs_part_2)\n","\n","sorted_list=[]\n","for index, row in df_quiz_abs_part_2.iterrows():\n","    scores = calculate_scores(row)\n","    sorted_list.append(scores)\n","df_quiz_abs_part_2 = pd.DataFrame(sorted_list, columns=['Q1', 'Q2', 'Q3', 'Q4', 'Q5','Q6'])\n","df_quiz_abs_part_2=df_quiz_abs_part_2.iloc[:,:-1]\n","#print(df_quiz_abs_part_2)\n","\n","\n","\n","df_sessional_I_part_2,df_sessional_II_part_2,Grades_data_part_2=df.iloc[:,16],df.iloc[:,17],df.iloc[:,18]\n","sf_sessional_I_part_2=(df_sessional_I_part_2/15)*15\n","sf_sessional_II_part_2=(df_sessional_II_part_2/15)*15\n","#print(df_sessional_I_part_2)\n","\n","df_part_2 = pd.concat([df_sessional_I_part_2,df_sessional_II_part_2,Grades_data_part_2], axis=1)\n","df_part_2 = pd.concat([df_part_2.iloc[:-3],df_part_2.iloc[-3:]], ignore_index=True)\n","\n","\n","# Concatenate DataFrames vertically (along rows)\n","df_part_2 = pd.concat([df_Assign_abs_part_2,df_quiz_abs_part_2,df_part_2], axis=1)\n","print(df_part_2)\n","\n","\n","x,y=df_part_2.iloc[:,0:12],df_part_2.iloc[:,12]\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","#print(x,y)\n","\n","\n","# Create a KNeighborsClassifier instance with k=3\n","knn = KNeighborsClassifier(n_neighbors=3)\n","\n","# Train the model\n","knn.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = knn.predict(X_test)\n","\n","# Calculate confusion matrix\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","\n","# Calculate specificity\n","specificity_KNN = specificity(tn , fp)\n","specificity_KNN=round(specificity_KNN,3)\n","\n","# Calculate sensitivity\n","sensitivity_KNN = sensitivity(tp , fn)\n","sensitivity_KNN=round(sensitivity_KNN,3)\n","\n","# Calculate accuracy\n","accuracy_KNN = accuracy(tn, fp, fn, tp)\n","accuracy_KNN=round(accuracy_KNN,3)\n","\n","# Evaluate the accuracy of the model\n","accuraccy = accuracy_score(y_test, y_pred)\n","accuraccy=round(accuraccy,3)\n","\n","print('')\n","print(\"\\n\\n\\n\\t Results of part II (K Nearest Neighbour) \\n \")\n","print(\"Accuracy of KNN           :\", accuraccy)\n","print(\"Accuracy(build in) of KNN :\", accuracy_KNN)\n","print(\"Specificity of KNN        :\", specificity_KNN)\n","print(\"Sensitivity of KNN        :\", sensitivity_KNN)\n","\n","\n","\n","\n","# Create the decision tree classifier\n","clf = tree.DecisionTreeClassifier(criterion='entropy')\n","\n","# Train the tree with the data\n","clf = clf.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = clf.predict(X_test)\n","\n","true_n, false_p, false_n, true_p = confusion_matrix(y_test, y_pred).ravel()\n","\n","# Calculate specificity\n","specificity_DT =specificity(true_n, false_p)\n","specificity_DT =round(specificity_DT,3)\n","\n","# Calculate sensitivity\n","sensitivity_DT = sensitivity(true_p , false_n)\n","sensitivity_DT =round(sensitivity_DT,3)\n","\n","# Evaluate the accuracy of the model\n","accuracy_DT = accuracy_score(y_test, y_pred)\n","accuracy_DT =round(accuracy_DT,3)\n","\n","print(\"\\n\\n\\n\\t Results of Part II (Decision Tree) \\n \")\n","print(\"Accuracy of DT   :\", accuracy_DT)\n","print(\"Specificity of DT:\", specificity_DT)\n","print(\"Sensitivity of DT:\", sensitivity_DT)\n","print('')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-ju-XBXA5EJ","executionInfo":{"status":"ok","timestamp":1714850533916,"user_tz":-300,"elapsed":774,"user":{"displayName":"Ayesha Saqib","userId":"15307684901972161499"}},"outputId":"2dd39704-f5cd-479a-a4b6-ece935e411e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      A1    A2    A3    A4    A5   Q1   Q2   Q3   Q4   Q5   S-I  S-II Grade\n","0   3.00  2.81  2.70  2.57  2.12  1.5  1.0  0.9  0.9  0.2  9.75  8.62  Pass\n","1   2.85  2.00  1.99  1.88  1.86  0.4  0.3  0.2  0.1  0.0  3.37  3.93  Fail\n","2   2.57  2.33  2.12  1.89  1.88  0.2  0.2  0.0  0.0  0.0  6.56  0.93  Fail\n","3   2.62  1.75  1.29  1.26  1.02  0.4  0.2  0.0  0.0  0.0  5.06  2.81  Fail\n","4   2.75  2.68  2.15  1.95  0.94  0.6  0.2  0.0  0.0  0.0  4.50  2.25  Fail\n","..   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...   ...   ...   ...\n","64  2.35  2.16  1.88  1.70  1.29  0.9  0.4  0.2  0.0  0.0  2.43  1.87  Fail\n","65  2.68  2.55  2.15  2.13  1.95  1.2  0.6  0.4  0.4  0.0  7.31  2.25  Fail\n","66  2.47  2.16  2.06  2.00  1.39  0.6  0.4  0.4  0.2  0.0  3.75  3.37  Fail\n","67  2.79  2.68  2.44  2.17  2.15  0.8  0.6  0.6  0.2  0.0  1.87  2.06  Fail\n","68  2.81  2.68  2.62  2.62  2.40  1.5  1.4  0.6  0.5  0.5  5.06  5.06  Pass\n","\n","[69 rows x 13 columns]\n","\n","\n","\n","\n","\t Results of part II (K Nearest Neighbour) \n"," \n","Accuracy of KNN           : 0.929\n","Accuracy(build in) of KNN : 0.929\n","Specificity of KNN        : 0.875\n","Sensitivity of KNN        : 1.0\n","\n","\n","\n","\t Results of Part II (Decision Tree) \n"," \n","Accuracy of DT   : 0.786\n","Specificity of DT: 0.75\n","Sensitivity of DT: 0.833\n","\n"]}]}]}